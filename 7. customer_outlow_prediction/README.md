# Отток клиентов из банка

## Описание проекта

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. У нас есть исторические данные о поведении клиентов и расторжении договоров с банком.

Перед нами стоит задача построить модель с предельно большим значением F1-меры (не менее 0.59). Дополнительно измерим AUC-ROC, сравним её значение с F1-мерой.

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

## Описание данных

**Признаки:**

- `RowNumber` — индекс строки в данных
- `CustomerId` — уникальный идентификатор клиента
- `Surname` — фамилия
- `CreditScore` — кредитный рейтинг
- `Geography` — страна проживания
- `Gender` — пол
- `Age` — возраст
- `Tenure` — сколько лет человек является клиентом банка
- `Balance` — баланс на счёте
- `NumOfProducts` — количество продуктов банка, используемых клиентом
- `HasCrCard` — наличие кредитной карты
- `IsActiveMember` — активность клиента
- `EstimatedSalary` — предполагаемая зарплата

**Целевой признак:**

- `Exited` — факт ухода клиента

## Выводы

- В первоначальные данных наблюдался значительный дисбаланс (80% ответов целевого признака были негативными и только 20% позитивными), из-за чего обученная на этих данных модель не проходила проверку на адекватность;

- Опытным путем мы пытались устранить дисбаланс классов тремя разными способами: `upsampling`, `downsampling`, параметр `class_weight = 'balanced'` при обучении модели. Как показали метрики финальной модели, в нашем случае метрики лучше при балансе классов способом увеличения выборки (upsampling);
также опытным путем мы выяснили, что наилучшие метрики достигаются на выборке, где пропуски ничем не заменялись, а просто удалялись;

- на сбалансированных данных все модели показали результат выше, чем на несбалансированной выборке. Лучшие показатели были у модели случайного леса;

- было принято решение продолжать улучшение модели RandomForestClassifier путем подбора параметров через цикл. Улучшение метрик зафиксировано при глубине - 15 и кол-ве деревьев - 100;

- при проверке финальной модели на адекватность с помощью сравнения метрик с метриками константной модели была подтверждена адекватность финальной модели.
